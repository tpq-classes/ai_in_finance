{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='http://hilpisch.com/taim_logo.png' width=\"350px\" align=\"right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Theory\n",
    "\n",
    "**Illustrated based on Numerical Examples**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dr Yves J Hilpisch | The AI Machine\n",
    "\n",
    "http://aimachine.io | http://twitter.com/dyjh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "!git clone https://github.com/tpq-classes/ai_in_finance.git\n",
    "import sys\n",
    "sys.path.append('ai_in_finance')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pylab import plt\n",
    "plt.style.use('seaborn-v0_8')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arbitrage Pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.array((0.5, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S0 = 10\n",
    "S = np.array((20, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B0 = 10\n",
    "B = np.array((11, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret(x, x0, P):\n",
    "    r = np.dot(x, P) / x0 - 1\n",
    "    return r.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret(S, S0, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret(B, B0, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array((S, B)).T\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M0 = np.array((S0, B0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.maximum(S - K, 0)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = np.linalg.solve(M, C)\n",
    "phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(M, phi).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C0 = np.dot(M0, phi)\n",
    "C0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret(C, C0, P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Martingale Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = ret(B, B0, P)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ES(Q):\n",
    "    return np.dot(S, Q) / (1 + r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ES(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ES(P) - S0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OF(Q):\n",
    "    return abs(ES(Q) - S0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OF(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnds = 2 * [(0, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons = {'type': 'eq', 'fun': lambda Q: Q.sum() - 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = minimize(OF, 2 * [1 / 2], bounds=bnds, constraints=cons)\n",
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = opt['x'].round(3)\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret(S, S0, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret(B, B0, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C0 = np.dot(C, Q) / (1 + r)\n",
    "C0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret(C, C0, Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Utility Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Varian (2010) introduces the concept of _utility_ and _utility functions_ as follows:\n",
    "\n",
    "> In Victorian days, philosophers and economists talked blithely of “utility”\n",
    "as an indicator of a person’s overall well-being. Utility was thought of as\n",
    "a numeric measure of a person’s happiness. Given this idea, it was natural\n",
    "to think of consumers making choices so as to maximize their utility, that\n",
    "is, to make themselves as happy as possible.\n",
    "\n",
    "> A utility function is a way of assigning a number to every possible\n",
    "consumption bundle such that more-preferred bundles get assigned larger\n",
    "numbers than less-preferred bundles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def u(c):\n",
    "    return np.sqrt(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def du(c):\n",
    "    return 0.5 / np.sqrt(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0.01, 3, 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, u(x), label='$u(c)$')\n",
    "plt.plot(x, du(x), label='$du(c)$')\n",
    "plt.xlabel('consumption or $c$')\n",
    "plt.ylabel('utility or $u(c)$')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Varian (2010) writes:\n",
    "\n",
    ">  Thus the expression $\\pi_1 u(c_1) + \\pi_2u(c_2)$\n",
    "represents the average utility, or the expected utility, of the pattern of\n",
    "consumption $(c_1, c_2)$.\n",
    "\n",
    "Above, $\\pi_s$ is the probabilty for state $s$ to unfold with $\\pi_1 + \\pi_2 = 1$. Accordingly, $c_s$ is consumption (wealth) in state $s$.\n",
    "\n",
    ">For this reason, we refer to a utility function with the particular form\n",
    "described here as an expected utility function, or, sometimes, a von\n",
    "Neumann-Morgenstern utility function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eu(M, phi, P):\n",
    "    w = np.dot(M, phi)\n",
    "    return np.dot(u(w), P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eu(M, (1.0, 0.0), P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eu(M, (0.75, 0.25), P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eu(M, (0.5, 0.5), P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eu(M, (0.25, 0.75), P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eu(M, (0.0, 1.0), P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnds = 2 * [(0, np.inf)]\n",
    "bnds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons = {'type': 'eq', 'fun': lambda phi: np.dot(M0, phi) - w0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = minimize(lambda phi: -Eu(M, phi, P), (2, 0.5),\n",
    "               bounds=bnds, constraints=cons)\n",
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = opt['x']\n",
    "phi.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eu(M, phi, P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representative Agent\n",
    "\n",
    "... or equilibrium pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MS = np.array(((1, 0), (0, 1))).T\n",
    "MS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = 1 / 1.1\n",
    "w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnds = 2 * [(0, np.inf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons = {'type': 'eq', 'fun': lambda p: np.sum(p) - w0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = minimize(lambda p: -Eu(MS, (1, 1), P), (1, 1),\n",
    "               bounds=bnds, constraints=cons)\n",
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = opt['x']\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S0 = np.dot(S, p)  # equilibrium pricing of the stock\n",
    "S0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret(S, S0, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B0 = np.dot(B, p)\n",
    "B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret(B, B0, P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M0 = np.array((S0, B0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = np.linalg.solve(M, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C0 = np.dot(M0, phi)\n",
    "C0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(C, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret(C, C0, P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modern Portfolio Theory (MPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sharpe (1964) points out:\n",
    "\n",
    "> Markowitz [(1952, 1959)] following Von Neumann and Morgenstern, developed an analysis based on the expected utility maxim and proposed a general solution for the portfolio selection problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markowitz (1952) postulates:\n",
    "\n",
    "> We next consider the rule that the investor does (or should) consider expected return a desirable thing and variance of return an undesirable thing. This rule has many sound points, both as a maxim for, and hypothesis about, investment behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Financial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://hilpisch.com/tr_eikon_eod_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv(url, index_col=0, parse_dates=True).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = ['AAPL.O', 'MSFT.O', 'INTC.O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw[symbols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets = np.log(data / data.shift(1)).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets.mean() * 252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets.std() * math.sqrt(252)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Portfolio Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = len(symbols) * [1 / len(symbols)]\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(rets.mean(), w) * 252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def port_return(w):\n",
    "    return np.dot(rets.mean(), w) * 252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_return(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(w, np.dot(rets.cov(), w)) * 252  # portfolio variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.sqrt(np.dot(w, np.dot(rets.cov(), w)) * 252)  # portfolio volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def port_volatility(w):\n",
    "    return math.sqrt(np.dot(w, np.dot(rets.cov(), w)) * 252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port_volatility(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw = np.random.random((N, len(symbols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw = (rw.T / rw.sum(axis=1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv = [(port_volatility(w), port_return(w))\n",
    "     for w in rw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv = np.array(pv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(pv[:, 0], pv[:, 1], 'ro')\n",
    "plt.ylabel('portfolio return')\n",
    "plt.xlabel('portfolio risk');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum Risk Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnds = len(symbols) * [(0, 1)]\n",
    "bnds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons = {'type': 'eq', 'fun': lambda w: w.sum() - 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = minimize(port_volatility, w, bounds=bnds, constraints=cons)\n",
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(pv[:, 0], pv[:, 1], 'r.',\n",
    "         label='random portfolios')\n",
    "plt.ylabel('portfolio return')\n",
    "plt.xlabel('portfolio risk')\n",
    "plt.plot(port_volatility(opt['x']),\n",
    "         port_return(opt['x']), 'yo',\n",
    "         ms=10, label='minimum risk portfolio')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empirical Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modern Portfoluo Theory (MPT) assumes that investors only care about **the first and second moment of the return distribution**.\n",
    "\n",
    "Only the **(log-)normal distribution** is fully characterized by its first moment (_expectation_) and second moment (_standard deviation_)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snrn = np.random.standard_normal(N)\n",
    "snrn -= snrn.mean()\n",
    "snrn /= snrn.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(snrn.mean(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(snrn.std(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(snrn, bins=35);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = np.ones(N) * 1.5\n",
    "split = int(0.25 * N)\n",
    "numbers[split:3 * split] = -1\n",
    "numbers[3 * split:4 * split] = 0\n",
    "numbers -= numbers.mean()\n",
    "numbers /= numbers.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(numbers.mean(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(numbers.std(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(numbers, bins=35);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -y statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as scs\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dN(x, mu, sigma):\n",
    "    ''' Probability density function of a normal random variable x.\n",
    "    '''\n",
    "    z = (x - mu) / sigma\n",
    "    pdf = np.exp(-0.5 * z ** 2) / math.sqrt(2 * math.pi * sigma ** 2)\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_histogram(rets):\n",
    "    ''' Plots a histogram of the returns.\n",
    "    '''\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    x = np.linspace(min(rets), max(rets), 100)\n",
    "    plt.hist(np.array(rets), bins=50, density=True)\n",
    "    y = dN(x, np.mean(rets), np.std(rets))\n",
    "    plt.plot(x, y, linewidth=2)\n",
    "    plt.xlabel('log returns')\n",
    "    plt.ylabel('frequency/probability')\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_histogram(snrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_histogram(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_qqplot(rets):\n",
    "    ''' Generates a Q-Q plot of the returns.\n",
    "    '''\n",
    "    sm.qqplot(rets, line='s')\n",
    "    plt.xlabel('theoretical quantiles')\n",
    "    plt.ylabel('sample quantiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_qqplot(snrn);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_qqplot(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics(rets):\n",
    "    print(\"RETURN SAMPLE STATISTICS\")\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(\"Skew of Sample Log Returns %9.6f\" % scs.skew(rets))\n",
    "    print(\"Skew Normal Test p-value   %9.6f\" % scs.skewtest(rets)[1])\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(\"Kurt of Sample Log Returns %9.6f\" % scs.kurtosis(rets))\n",
    "    print(\"Kurt Normal Test p-value   %9.6f\" % \\\n",
    "                scs.kurtosistest(rets)[1])\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(\"Normal Test p-value        %9.6f\" % \\\n",
    "                scs.normaltest(rets)[1])\n",
    "    print(\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_statistics(snrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_statistics(numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-World Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = ['.SPX', 'EUR=', 'GLD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets = np.log(raw[symbols] / raw[symbols].shift(1)).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sym in symbols:\n",
    "    return_histogram(rets[sym].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sym in symbols:\n",
    "    return_qqplot(rets[sym].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sym in symbols:\n",
    "    print('\\n{}'.format(sym))\n",
    "    print(45 * '=')\n",
    "    print_statistics(rets[sym].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for weights in [w, opt['x']]:\n",
    "    return_histogram(np.dot(rets, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for weights in [w, opt['x']]:\n",
    "    return_qqplot(np.dot(rets, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for weights in [w, opt['x']]:\n",
    "    print()\n",
    "    print_statistics(np.dot(rets, weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capital Asset Pricing Model (CAPM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sharpe (1964) assumes the following:\n",
    "\n",
    "> In order to derive conditions for equilibriumin the capital market we invoke two assumptions. First, we assume a common pure rate of interest, with all investors able to borrow or lend funds on equal terms. Second, weassume homogeneity of investor expectations: investors are assumed to agree on the prospects of various investments &mdash; the expected values, standard deviations and correlation coefficients ... Needless to say, these are highly restrictive and undoubtedly unrealistic assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the CAPM, the expected return for a stock (financial asset) is given by the following relationship:\n",
    "\n",
    "$$\\mu_S = r + \\beta \\cdot (\\mu_M - r)$$\n",
    "\n",
    "Here, $r$ is the riskless short rate, $\\beta_S$ is a stock-specific factor to be determined through statistical methods and $\\mu_M$ is the expected return of the market portfolio. $\\beta_S$ is given by\n",
    "\n",
    "$$\\beta = \\frac{\\sigma_{SM}}{\\sigma^2_M}$$\n",
    "\n",
    "with $\\sigma_{SM}$ as the covariance between the stock and the market portfolio and $\\sigma^2_M$ the variance of the market's returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = ['AAPL.O', '.SPX']\n",
    "market = '.SPX'\n",
    "data = raw[symbols]\n",
    "rets = np.log(data / data.shift(1)).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets.plot(kind='scatter', x=market, y=symbols[0], figsize=(10, 6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formualic Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets.cov() * 252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = rets.cov().iloc[0, -1] * 252\n",
    "cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets.var() * 252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = rets[market].var() * 252\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muM = rets[market].mean() * 252\n",
    "muM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = cov / var\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muS = r + beta * (muM - r)\n",
    "muS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets[symbols[0]].mean() * 252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets = np.log(raw / raw.shift(1)).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = raw.columns[:7]\n",
    "symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sym in raw.columns[:5]:\n",
    "    print('\\n' + sym)\n",
    "    print(45 * '=')\n",
    "    cov = rets.cov().loc[sym, '.SPX'] \n",
    "    var = rets['.SPX'].var()\n",
    "    beta = cov / var\n",
    "    muS = r + beta * (muM - r)\n",
    "    mean =  rets[sym].mean() * 252\n",
    "    print('beta: {:.3f} | mu: {:.3f} | mean: {:.3f}'.format(beta, muS, mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = np.polyfit(rets[symbols[-1]], rets[symbols[0]], deg=1)\n",
    "reg.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = np.polyfit(rets[symbols[-1]] - r, rets[symbols[0]] - r, deg=1)\n",
    "reg.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets.plot(kind='scatter', x=symbols[-1],\n",
    "          y=symbols[0], figsize=(10, 6))\n",
    "plt.plot(rets[symbols[-1]], np.polyval(reg, rets[symbols[-1]]), 'r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = reg[0]\n",
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muS = r + beta * (muM - r)\n",
    "muS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets[symbols[0]].mean() * 252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()\n",
    "for sym in raw.columns[:5]:\n",
    "    print('\\n' + sym)\n",
    "    print(45 * '=')\n",
    "    beta = np.polyfit(rets['.SPX'],\n",
    "                      rets[sym], deg=1)[0]\n",
    "    muS = muS = r + beta * (muM - r)\n",
    "    mean =  rets[sym].mean() * 252\n",
    "    print('beta: {:.3f} | mu: {:.3f} | mean: {:.3f}'.format(beta, muS, mean))\n",
    "    res = pd.concat((res, pd.DataFrame({'sym': sym, 'beta': beta,\n",
    "                                   'mu': muS, 'mean': mean}, index=[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = res.round(3).set_index('sym').plot(kind='bar', figsize=(10, 6),\n",
    "                                  secondary_y='beta')\n",
    "ax.get_legend().set_bbox_to_anchor((0.2, 1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[['beta', 'mean']].plot(kind='scatter', x='beta',\n",
    "                         y='mean', figsize=(10, 6))\n",
    "x = np.linspace(res['beta'].min(), res['beta'].max())\n",
    "reg = np.polyfit(res['beta'], res['mean'], deg=1)\n",
    "plt.plot(x, np.polyval(reg, x), 'g--', label='regression')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()\n",
    "years = range(2010, 2019)\n",
    "for sym in raw.columns[:5]:\n",
    "    for year in years:\n",
    "        sel = rets[(rets.index >= '01-01-{}'.format(year)) &\n",
    "                  (rets.index <= '31-12-{}'.format(year))]\n",
    "        \n",
    "        beta = np.polyfit(sel[market],\n",
    "                          sel[sym], deg=1)[0]\n",
    "        muM = sel[market].mean() * 252\n",
    "        muS = r + beta * (muM - r)\n",
    "        mean =  sel[sym].mean() * 252\n",
    "        if pr:\n",
    "            print('\\n' + sym + '| {}'.format(year))\n",
    "            print(45 * '=')\n",
    "            print('beta: {:.3f} | mu: {:.3f} | mean: {:.3f}'\n",
    "                  .format(beta, muS, mean))\n",
    "        res = pd.concat((res, pd.DataFrame({'sym': sym, 'year': year, 'beta': beta,\n",
    "                                       'mu': muS, 'mean': mean}, index=[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[['mu', 'mean']].plot(kind='scatter', x='mu',\n",
    "                         y='mean', figsize=(10, 6))\n",
    "x = np.linspace(res['mu'].min(), res['mu'].max())\n",
    "r = np.polyfit(res['mu'], res['mean'], deg=1)\n",
    "plt.plot(x, x, 'r', label='identity')\n",
    "plt.plot(x, np.polyval(r, x), 'g--', label='regression')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[['beta', 'mean']].plot(kind='scatter', x='beta',\n",
    "                         y='mean', figsize=(10, 6))\n",
    "x = np.linspace(res['beta'].min(), res['beta'].max())\n",
    "r = np.polyfit(res['beta'], res['mean'], deg=1)\n",
    "plt.plot(x, np.polyval(r, x), 'g--', label='regression')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Factor Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ross (1976) introduces as follows:\n",
    "\n",
    "> The purpose of this paper is to examine rigorously the arbitrage model of capital asset pricing developed in Ross (1971). The arbitrage model was proposed as an alternative to the mean variance capital asset pricing model, introduced by Sharpe, Lintner, and Treynor, that has become the major analytic tool for explaining phenomena observed in capital markets for risky assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym = 'INTC.O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market = ['.SPX', '.VIX', 'EUR=', 'XAU=']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = np.linalg.lstsq(rets[market], rets[sym], rcond=-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(rets[market].mean() * 252, reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets[sym].mean() * 252"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()\n",
    "years = range(2010, 2019)\n",
    "for sym in raw.columns[:5]:\n",
    "    for year in years:\n",
    "        sel = rets[(rets.index >= '01-01-{}'.format(year)) &\n",
    "                  (rets.index <= '31-12-{}'.format(year))]\n",
    "        \n",
    "        beta = np.linalg.lstsq(sel[market],\n",
    "                          sel[sym], rcond=-1)[0]\n",
    "        muM = sel[market].mean() * 252\n",
    "        muS = np.dot(muM, beta)\n",
    "        mean =  sel[sym].mean() * 252\n",
    "        if pr:\n",
    "            print('\\n' + sym + '| {}'.format(year))\n",
    "            print(45 * '=')\n",
    "            print('beta: {:.3} | mu: {:.3f} | mean: {:.3f}'\n",
    "                  .format(beta, muS, mean))\n",
    "        res = pd.concat((res, pd.DataFrame({'sym': sym, 'year': year, 'beta': beta.sum(),\n",
    "                                       'mu': muS, 'mean': mean}, index=[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[res['sym'] == 'MSFT.O'].set_index('year')[['mu', 'mean']].plot(kind='bar', figsize=(10, 6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[['mu', 'mean']].plot(kind='scatter', x='mu',\n",
    "                         y='mean', figsize=(10, 6))\n",
    "x = np.linspace(res['mu'].min(), res['mu'].max())\n",
    "r = np.polyfit(res['mu'], res['mean'], deg=1)\n",
    "plt.plot(x, x, 'r', label='identity')\n",
    "plt.plot(x, np.polyval(r, x), 'g--', label='regression')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Looking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()\n",
    "years = range(2010, 2019)\n",
    "for sym in raw.columns[:5]:\n",
    "    for year in years:\n",
    "        sel = rets[(rets.index >= '01-01-{}'.format(year)) &\n",
    "                  (rets.index <= '31-12-{}'.format(year))]\n",
    "        sel_ = rets[(rets.index >= '01-01-{}'.format(year+1)) &\n",
    "                  (rets.index <= '31-12-{}'.format(year+1))]\n",
    "        \n",
    "        beta = np.linalg.lstsq(sel[market],\n",
    "                          sel[sym], rcond=-1)[0]\n",
    "        muM = sel_[market].mean() * 252\n",
    "        muS = np.dot(muM, beta)\n",
    "        mean =  sel_[sym].mean() * 252\n",
    "        if pr:\n",
    "            print('\\n' + sym + '| {}'.format(year))\n",
    "            print(45 * '=')\n",
    "            print('beta: {:.3} | mu: {:.3f} | mean: {:.3f}'\n",
    "                  .format(beta, muS, mean))\n",
    "        res = pd.concat((res, pd.DataFrame({'sym': sym, 'year': year, 'beta': beta.sum(),\n",
    "                                       'mu': muS, 'mean': mean}, index=[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[res['sym'] == 'MSFT.O'].set_index('year')[['mu', 'mean']].plot(kind='bar', figsize=(10, 6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[['mu', 'mean']].plot(kind='scatter', x='mu',\n",
    "                         y='mean', figsize=(10, 6))\n",
    "x = np.linspace(res['mu'].min(), res['mu'].max())\n",
    "r = np.polyfit(res['mu'], res['mean'], deg=1)\n",
    "plt.plot(x, x, 'r', label='identity')\n",
    "plt.plot(x, np.polyval(r, x), 'g--', label='regression')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jolliffe and Cadima (2016) summarize:\n",
    "\n",
    "> Large datasets are increasingly common and are often difficult to interpret. Principal component analysis (PCA) is a technique for reducing the dimensionality of such datasets, increasing interpretability but at the same time minimizing information loss. It does so by creating new uncorrelated variables that successively maximize variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit_transform(rets.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(pca.n_components), pca.explained_variance_ratio_);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = pd.DataFrame()\n",
    "for i, w in enumerate(pca.components_):\n",
    "    pc['pc_{}'.format(i)] = np.dot(rets.iloc[:, 1:], w)\n",
    "pc.index = rets.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()\n",
    "years = range(2010, 2019)\n",
    "for sym in raw.columns[:5]:\n",
    "    for year in years:\n",
    "        sel = rets[(rets.index >= '01-01-{}'.format(year)) &\n",
    "                  (rets.index <= '31-12-{}'.format(year))]\n",
    "        sel_ = pc[(pc.index >= '01-01-{}'.format(year)) &\n",
    "                  (pc.index <= '31-12-{}'.format(year))]\n",
    "        beta = np.linalg.lstsq(sel_,\n",
    "                          sel[sym], rcond=-1)[0]\n",
    "        muM = sel_.mean() * 252\n",
    "        muS = np.dot(muM, beta)\n",
    "        mean = sel[sym].mean() * 252\n",
    "        if pr:\n",
    "            print('\\n' + sym + '| {}'.format(year))\n",
    "            print(45 * '=')\n",
    "            print('beta: {:.3} | mu: {:.3f} | mean: {:.3f}'\n",
    "                  .format(beta, muS, mean))\n",
    "        res = pd.concat((res, pd.DataFrame({'sym': sym, 'year': year, 'beta': beta.sum(),\n",
    "                                       'mu': muS, 'mean': mean}, index=[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[res['sym'] == 'AMZN.O'].set_index('year')[['mu', 'mean']].plot(kind='bar', figsize=(10, 6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[['mu', 'mean']].plot(kind='scatter', x='mu',\n",
    "                         y='mean', figsize=(10, 6))\n",
    "x = np.linspace(res['mu'].min(), res['mu'].max())\n",
    "r = np.polyfit(res['mu'], res['mean'], deg=1)\n",
    "plt.plot(x, x, 'r', label='identity')\n",
    "plt.plot(x, np.polyval(r, x), 'g--', label='regression')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Markowitz, Harry (1952): &ldquo;Portfolio Selection.&rdquo; _Journal of Finance_, Vol. 7, No. 1, 77-91.\n",
    "* Markowitz, Harry (1959): _Portfolio Selection._ John Wiley & Sons, New York.\n",
    "* Ross, Stephen (1976): &ldquo;The Arbitrage Theory of Capital Asset Pricing.&rdquo; _Journal of Economic Theory_, Vol 13, 341-360.\n",
    "* Sharpe, William (1964): &ldquo;Capital Asset Prices: A Theory of Market Equibrium under Conditions of Risk&rdquo; _Journal of Finance_, Vol. 19, No. 3, 425-442.\n",
    "* Varian, Hal (2010): _Intermediate Microeconomics._ W.W.Norton & Company, New York & London.\n",
    "* Jolliffe, Ian and Jorge Cadima (2006): &ldquo;Principal Component Analysis: A Review and Recent Developments.&rdquo; Philosophical Transactions, Vol. 374, 1-16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='http://hilpisch.com/taim_logo.png' width=\"350px\" align=\"right\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}